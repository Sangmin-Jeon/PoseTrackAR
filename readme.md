# 실시간 3D 객체 인식 및 거리 추정 앱

<br>

## #1 프로젝트 목표

이 프로젝트의 핵심 목표는 **단일 카메라만으로 특정 3D 객체와의 거리를 정밀하게 추정**하는 것입니다. 이를 위해 최신 딥러닝 기술과 전통적인 컴퓨터 비전 알고리즘을 결합하여, 다음과 같은 문제를 해결하는 데 주력했습니다.

- **정확성:** 노이즈가 많은 실시간 영상 환경에서도 신뢰할 수 있는 거리 값을 계산합니다.
- **안정성:** 카메라나 객체가 움직일 때, 계산된 거리 값이 갑자기 튀거나 흔들리지 않도록 안정화합니다.
- **실시간성:** 모든 과정이 iOS 디바이스에서 실시간으로 동작하도록 파이프라인을 최적화합니다.

<br>

## #2 핵심 기술 스택

- **언어:** Swift, C++
- **프레임워크:** ARKit, Core ML, SwiftUI, Combine
- **라이브러리:** OpenCV (C++)
- **딥러닝 모델:** YOLOv11 (객체 탐지용)

<br>

## #3 핵심 파이프라인: "탐지 후 추정 (Detection-then-Estimation)"

본 프로젝트는 컴퓨터 비전 분야에서 널리 사용되는 안정적인 **"탐지 후 추정"** 파이프라인을 기반으로 구현되었습니다.

1.  **탐지 (Detection) - by YOLOv11:**
    * `ARSession`으로부터 매 프레임마다 실시간 카메라 영상을 받아옵니다.
    * **YOLOv11** 모델이 영상 전체를 빠르게 스캔하여 목표 객체("friend")의 위치를 **바운딩 박스(ROI)**로 찾아냅니다.
    * 이 단계는 "객체가 화면 어디에 있는가?"를 먼저 알아내어, 불필요한 배경 영역을 계산에서 제외하는 매우 중요한 역할을 합니다.

2.  **추정 (Estimation) - by OpenCV:**
    * **관심 영역(ROI) 처리:** YOLO가 찾은 바운딩 박스 안에서만 다음 계산을 수행하여, 계산 효율과 정확도를 극대화합니다.
    * **특징점 매칭:** ROI 내부에서 **ORB** 알고리즘으로 수백 개의 특징점을 찾고, 미리 학습된 **참조 객체의 8개 랜드마크 '지문'(Descriptor)과 비교**하여 2D-3D 대응점 쌍을 찾습니다. (`BFMatcher`와 `knnMatch` 사용)
    * **자세 계산:** 이 대응점 쌍을 **`solvePnPRansac`** 에 입력하여, 카메라로부터 객체까지의 3D 위치(`tvec`)와 방향(`rvec`)을 계산합니다.

3.  **결과 안정화 (Filtering & Smoothing):**
    * **1차 필터링 (C++):** 계산된 결과가 비현실적이거나(예: 거리 5m 초과) 수학적으로 불안정(`nan`, `inf`)하면 폐기합니다.
    * **2차 필터링 (Swift):** C++에서 전달된 유효한 값들을 **이동 평균 필터(Moving Average Filter)**로 부드럽게 보정하여, 최종적으로 UI에 안정적인 거리 값을 표시합니다.

<br>

## #4 개발 과정에서 마주한 문제 및 해결 과정 (Troubleshooting)

#### 문제 1: PnP 결과가 완전히 틀어지는 현상
- **증상:** 최초 구현 시, PnP 결과가 엄청난 값으로 튀거나 전혀 계산되지 않음.
- **원인 분석:** `goodFeaturesToTrack`을 사용한 초기 접근 방식은 2D-3D 대응점의 순서를 보장하지 못했기 때문.   
PnP는 3D 기준점과 그에 해당하는 2D 이미지 점이 정확히 짝이라는 가정 하에 동작하는데, 이 가정이 깨져있었음.

- **해결책:** **ORB 특징점 기술자(Descriptor)**를 도입. 참조 이미지에서 8개 랜드마크의 고유한 '지문'을 미리 추출하고, 실시간 영상의 특징점 지문과 비교하여 신뢰도 높은 대응 관계를 확립하는 방식으로 변경.

#### 문제 2: 거리가 멀어져도 `9.3cm`와 같은 특정 값으로 고정되는 문제
- **증상:** 객체와의 실제 거리를 바꾸어도, 계산된 거리는 거의 변하지 않음.
- **원인 분석:** PnP 알고리즘이 "멀리 있는 큰 객체"와 "가까이 있는 작은 객체"를 구분하지 못하는 기하학적 모호성에 빠짐. 특히 3D 모델의 Z좌표가 모두 0일 때(평면일 때)와 `SOLVEPNP_ITERATIVE` 솔버 사용 시 이 문제가 두드러짐.
- **해결책:**
    1.  **3D 모델 입체화:** `object_3d_points`에 실제 깊이를 반영한 Z좌표를 부여하여 평면이 아님을 명시.
    2.  **PnP 솔버 교체:** 모호성에 더 강건한 최신 솔버인 `SOLVEPNP_AP3P`로 교체하여 문제를 최종 해결.

#### 문제 3: 엉뚱한 배경에서 PnP가 오작동하는 현상
- **증상:** 객체가 없어도 배경의 특정 무늬를 객체로 착각하여 PnP가 계산되고, 값이 튀거나 `nan`이 출력됨.
- **원인 분석:** **"탐지" 단계의 부재.** 시스템이 화면 전체를 대상으로 무작정 특징점 매칭을 시도했기 때문.
- **해결책:** **YOLOv11을 이용한 "탐지 후 추정" 파이프라인 도입.** YOLO가 먼저 객체의 위치(ROI)를 찾아주면, 그 안에서만 특징점 매칭을 수행하도록 로직을 변경. 이로써 배경과의 오매칭을 원천적으로 차단하고 계산 성능을 향상시킴.


